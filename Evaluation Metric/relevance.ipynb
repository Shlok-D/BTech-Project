{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7927028,"sourceType":"datasetVersion","datasetId":4524856},{"sourceId":7981394,"sourceType":"datasetVersion","datasetId":4697663},{"sourceId":7992115,"sourceType":"datasetVersion","datasetId":4572300}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T10:21:36.238384Z","iopub.execute_input":"2024-04-14T10:21:36.239434Z","iopub.status.idle":"2024-04-14T10:21:37.181834Z","shell.execute_reply.started":"2024-04-14T10:21:36.239401Z","shell.execute_reply":"2024-04-14T10:21:37.180884Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/marathi-summarization-dataset/marathi-marathi_val.jsonl\n/kaggle/input/marathi-summarization-dataset/marathi-marathi_train.jsonl\n/kaggle/input/marathi-summarization-dataset/marathi-marathi_test.jsonl\n/kaggle/input/summarisaton-mar-emg/mar_eng_sum.csv\n/kaggle/input/english-summarization-dataset/test_final_eng.csv\n/kaggle/input/english-summarization-dataset/val_final_eng.csv\n/kaggle/input/english-summarization-dataset/train_final_eng.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Path to the JSON Lines file\nfile_path = [\"/kaggle/input/marathi-summarization-dataset/marathi-marathi_test.jsonl\", \"/kaggle/input/marathi-summarization-dataset/marathi-marathi_train.jsonl\",\"/kaggle/input/marathi-summarization-dataset/marathi-marathi_val.jsonl\"]\n\n\n# Initialize an empty list to hold the JSON objects\ndata = []\n\n# Open the file and read line by line\nfor i in range(3):\n    data.append([])\n    with open(file_path[i], 'r', encoding='utf-8') as file:\n        for line in file:\n            # Parse each line as a JSON object and append to the list\n            data[i].append(json.loads(line))\n    \n\n# Convert the list of JSON objects into a DataFrame\ndf_mr = pd.DataFrame(data[1])\ndf_test_cs_mar = pd.DataFrame(data[0])\ndf_val_cs_mar = pd.DataFrame(data[2])\n\n# Display the first few rows of the DataFrame to check if it's loaded correctly\nprint(len(df_mr))\nprint(len(df_test_cs_mar))\nprint(len(df_val_cs_mar))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:39.260118Z","iopub.execute_input":"2024-04-14T10:21:39.260632Z","iopub.status.idle":"2024-04-14T10:21:42.980242Z","shell.execute_reply.started":"2024-04-14T10:21:39.260600Z","shell.execute_reply":"2024-04-14T10:21:42.979294Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"10558\n1188\n1254\n","output_type":"stream"}]},{"cell_type":"code","source":"df_val_cs_mar.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:42.982013Z","iopub.execute_input":"2024-04-14T10:21:42.982373Z","iopub.status.idle":"2024-04-14T10:21:42.989369Z","shell.execute_reply.started":"2024-04-14T10:21:42.982338Z","shell.execute_reply":"2024-04-14T10:21:42.988550Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['source_url', 'target_url', 'text', 'summary'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf_en=pd.read_csv(\"/kaggle/input/english-summarization-dataset/train_final_eng.csv\")\ndf_en.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:44.511910Z","iopub.execute_input":"2024-04-14T10:21:44.512243Z","iopub.status.idle":"2024-04-14T10:21:49.206300Z","shell.execute_reply.started":"2024-04-14T10:21:44.512218Z","shell.execute_reply":"2024-04-14T10:21:49.205340Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['source_url', 'target_url', 'text', 'summary'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df_en_test=pd.read_csv(\"/kaggle/input/english-summarization-dataset/test_final_eng.csv\")\ndf_en_test.columns\ndf_en_val=pd.read_csv(\"/kaggle/input/english-summarization-dataset/val_final_eng.csv\")\ndf_en_val.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:49.207917Z","iopub.execute_input":"2024-04-14T10:21:49.208209Z","iopub.status.idle":"2024-04-14T10:21:49.910742Z","shell.execute_reply.started":"2024-04-14T10:21:49.208184Z","shell.execute_reply":"2024-04-14T10:21:49.909728Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Index(['source_url', 'target_url', 'text', 'summary'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv(\"/kaggle/input/summarisaton-mar-emg/mar_eng_sum.csv\")\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:49.911933Z","iopub.execute_input":"2024-04-14T10:21:49.912223Z","iopub.status.idle":"2024-04-14T10:21:50.381831Z","shell.execute_reply.started":"2024-04-14T10:21:49.912199Z","shell.execute_reply":"2024-04-14T10:21:50.380889Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Index(['url', 'text_mr', 'summary_en', 'summary_mr', 'text_en'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"print(\"NaNs in df_en 'text':\", df_en['text'].isnull().sum())\nprint(\"NaNs in df_mr 'text':\", df_mr['text'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:53.809423Z","iopub.execute_input":"2024-04-14T10:21:53.809805Z","iopub.status.idle":"2024-04-14T10:21:53.833043Z","shell.execute_reply.started":"2024-04-14T10:21:53.809775Z","shell.execute_reply":"2024-04-14T10:21:53.831941Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"NaNs in df_en 'text': 0\nNaNs in df_mr 'text': 0\n","output_type":"stream"}]},{"cell_type":"code","source":"df_en = df_en.sample(n=20000, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:57.189051Z","iopub.execute_input":"2024-04-14T10:21:57.189425Z","iopub.status.idle":"2024-04-14T10:21:57.218144Z","shell.execute_reply.started":"2024-04-14T10:21:57.189378Z","shell.execute_reply":"2024-04-14T10:21:57.217346Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_en.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:21:58.864433Z","iopub.execute_input":"2024-04-14T10:21:58.864881Z","iopub.status.idle":"2024-04-14T10:21:58.873270Z","shell.execute_reply.started":"2024-04-14T10:21:58.864852Z","shell.execute_reply":"2024-04-14T10:21:58.872415Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Index(['source_url', 'target_url', 'text', 'summary'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"print(df_en.isna().sum())","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"source_url    0\ntarget_url    0\ntext          0\nsummary       0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Label relevant pairs with '1'\ndf_en['relevance'] = 1\ndf_mr['relevance'] = 1\n# Shuffle texts within each DataFrame to create irrelevant pairs\n# Reset index before sampling to ensure alignment\ndf_en_reset = df_en.reset_index(drop=True)\ndf_mr_reset = df_mr.reset_index(drop=True)\n\ndf_en_irrelevant = df_en_reset.copy().assign(text=df_en_reset['text'].sample(frac=1).reset_index(drop=True), relevance=0)\ndf_mr_irrelevant = df_mr_reset.copy().assign(text=df_mr_reset['text'].sample(frac=1).reset_index(drop=True), relevance=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:02.933391Z","iopub.execute_input":"2024-04-14T10:22:02.934074Z","iopub.status.idle":"2024-04-14T10:22:02.962173Z","shell.execute_reply.started":"2024-04-14T10:22:02.934038Z","shell.execute_reply":"2024-04-14T10:22:02.960996Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Combine relevant and irrelevant pairs for each language\ndf_en_combined = pd.concat([df_en, df_en_irrelevant])\ndf_mr_combined = pd.concat([df_mr, df_mr_irrelevant])\n\n# Combine English and Marathi data\ndf_combined = pd.concat([df_en_combined, df_mr_combined], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:04.762959Z","iopub.execute_input":"2024-04-14T10:22:04.763706Z","iopub.status.idle":"2024-04-14T10:22:04.782978Z","shell.execute_reply.started":"2024-04-14T10:22:04.763663Z","shell.execute_reply":"2024-04-14T10:22:04.782248Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Check for NaNs after combining\nprint(\"NaNs in combined 'text':\", df_combined['text'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:06.519038Z","iopub.execute_input":"2024-04-14T10:22:06.519773Z","iopub.status.idle":"2024-04-14T10:22:06.535381Z","shell.execute_reply.started":"2024-04-14T10:22:06.519740Z","shell.execute_reply":"2024-04-14T10:22:06.534492Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"NaNs in combined 'text': 0\n","output_type":"stream"}]},{"cell_type":"code","source":"df_combined.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:08.128974Z","iopub.execute_input":"2024-04-14T10:22:08.129318Z","iopub.status.idle":"2024-04-14T10:22:08.135440Z","shell.execute_reply.started":"2024-04-14T10:22:08.129290Z","shell.execute_reply":"2024-04-14T10:22:08.134561Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Index(['source_url', 'target_url', 'text', 'summary', 'relevance'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"# Shuffle the combined DataFrame to ensure a random distribution of data\ndf_combined = df_combined.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:09.859163Z","iopub.execute_input":"2024-04-14T10:22:09.859529Z","iopub.status.idle":"2024-04-14T10:22:09.907602Z","shell.execute_reply.started":"2024-04-14T10:22:09.859488Z","shell.execute_reply":"2024-04-14T10:22:09.906659Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(len(df_combined))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:11.575007Z","iopub.execute_input":"2024-04-14T10:22:11.575682Z","iopub.status.idle":"2024-04-14T10:22:11.580323Z","shell.execute_reply.started":"2024-04-14T10:22:11.575648Z","shell.execute_reply":"2024-04-14T10:22:11.579405Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"61116\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df_combined.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:13.229628Z","iopub.execute_input":"2024-04-14T10:22:13.229968Z","iopub.status.idle":"2024-04-14T10:22:13.274171Z","shell.execute_reply.started":"2024-04-14T10:22:13.229941Z","shell.execute_reply":"2024-04-14T10:22:13.273289Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"source_url    0\ntarget_url    0\ntext          0\nsummary       0\nrelevance     0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df_en and df_mr are your English and Marathi DataFrames respectively\n# Sampling 10,000 rows from each DataFrame\ndf_en_sample = df_en.sample(n=10000, random_state=42)  # English DataFrame\ndf_mr_sample = df_mr.sample(n=10000, random_state=42)  # Marathi DataFrame","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:15.019474Z","iopub.execute_input":"2024-04-14T10:22:15.020314Z","iopub.status.idle":"2024-04-14T10:22:15.031742Z","shell.execute_reply.started":"2024-04-14T10:22:15.020283Z","shell.execute_reply":"2024-04-14T10:22:15.030794Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Reset index to align the samples\ndf_en_sample.reset_index(drop=True, inplace=True)\ndf_mr_sample.reset_index(drop=True, inplace=True)\n\n# Create cross-lingual irrelevant pairs\n# English text with Marathi summary\ndf_en_mr_irrelevant = pd.DataFrame({\n    'text': df_en_sample['text'],\n    'summary': df_mr_sample['summary'],\n    'relevance': 0  # Mark as irrelevant\n})\n\n# Marathi text with English summary\ndf_mr_en_irrelevant = pd.DataFrame({\n    'text': df_mr_sample['text'],\n    'summary': df_en_sample['summary'],\n    'relevance': 0  # Mark as irrelevant\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:16.889314Z","iopub.execute_input":"2024-04-14T10:22:16.890209Z","iopub.status.idle":"2024-04-14T10:22:16.898469Z","shell.execute_reply.started":"2024-04-14T10:22:16.890175Z","shell.execute_reply":"2024-04-14T10:22:16.897646Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def create_relevance_dataset(df):\n    # Correct Pairings with relevance = 1\n    correct_pairs_en = df[['summary_en', 'text_en']].rename(columns={'summary_en': 'summary', 'text_en': 'text'})\n    correct_pairs_en['relevance'] = 1\n    \n    correct_pairs_mr = df[['summary_mr', 'text_mr']].rename(columns={'summary_mr': 'summary', 'text_mr': 'text'})\n    correct_pairs_mr['relevance'] = 1\n\n    # Incorrect Pairings with relevance = 0\n    # Shuffle the texts and pair with the original summaries\n    wrong_texts_en = df['text_en'].sample(frac=1).reset_index(drop=True)\n    incorrect_pairs_en = pd.DataFrame({'summary': df['summary_en'], 'text': wrong_texts_en})\n    incorrect_pairs_en['relevance'] = 0\n\n    wrong_texts_mr = df['text_mr'].sample(frac=1).reset_index(drop=True)\n    incorrect_pairs_mr = pd.DataFrame({'summary': df['summary_mr'], 'text': wrong_texts_mr})\n    incorrect_pairs_mr['relevance'] = 0\n\n    # Combine all pairs\n    combined_dataset = pd.concat([correct_pairs_en, correct_pairs_mr, incorrect_pairs_en, incorrect_pairs_mr])\n    \n    # Shuffle the combined dataset\n    combined_dataset = combined_dataset.sample(frac=1).reset_index(drop=True)\n\n    return combined_dataset\n\n# Create the relevance dataset\nrelevance_dataset = create_relevance_dataset(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:19.098973Z","iopub.execute_input":"2024-04-14T10:22:19.099599Z","iopub.status.idle":"2024-04-14T10:22:19.116295Z","shell.execute_reply.started":"2024-04-14T10:22:19.099567Z","shell.execute_reply":"2024-04-14T10:22:19.115461Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def create_relevance_dataset_2(df):\n    # Correct Pairings with relevance = 1\n    correct_pairs_en = df[['summary_en', 'text_mr']].rename(columns={'summary_en': 'summary', 'text_mr': 'text'})\n    correct_pairs_en['relevance'] = 1\n    \n    correct_pairs_mr = df[['summary_mr', 'text_en']].rename(columns={'summary_mr': 'summary', 'text_en': 'text'})\n    correct_pairs_mr['relevance'] = 1\n\n    # Incorrect Pairings with relevance = 0\n    # Shuffle the texts and pair with the original summaries\n    wrong_texts_en = df['text_en'].sample(frac=1).reset_index(drop=True)\n    incorrect_pairs_en = pd.DataFrame({'summary': df['summary_mr'], 'text': wrong_texts_en})\n    incorrect_pairs_en['relevance'] = 0\n\n    wrong_texts_mr = df['text_mr'].sample(frac=1).reset_index(drop=True)\n    incorrect_pairs_mr = pd.DataFrame({'summary': df['summary_en'], 'text': wrong_texts_mr})\n    incorrect_pairs_mr['relevance'] = 0\n\n    # Combine all pairs\n    combined_dataset = pd.concat([correct_pairs_en, correct_pairs_mr, incorrect_pairs_en, incorrect_pairs_mr])\n    \n    # Shuffle the combined dataset\n    combined_dataset = combined_dataset.sample(frac=1).reset_index(drop=True)\n\n    return combined_dataset\n\n# Create the relevance dataset\nrelevance_dataset_2 = create_relevance_dataset_2(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:21.750115Z","iopub.execute_input":"2024-04-14T10:22:21.750880Z","iopub.status.idle":"2024-04-14T10:22:21.765932Z","shell.execute_reply.started":"2024-04-14T10:22:21.750846Z","shell.execute_reply":"2024-04-14T10:22:21.765035Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(relevance_dataset['relevance'][1],relevance_dataset['summary'][1])","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:24.399124Z","iopub.execute_input":"2024-04-14T10:22:24.399475Z","iopub.status.idle":"2024-04-14T10:22:24.405203Z","shell.execute_reply.started":"2024-04-14T10:22:24.399446Z","shell.execute_reply":"2024-04-14T10:22:24.404123Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0 सौदी अरेबिया आणि इराणमधला संघर्ष फार जुना आहे. वर्षानुवर्षं हे देश एकमेकांचे विरोधक आहेत. पण गेल्या काही दिवसांमध्ये या दोन देशांतला तणाव वाढला आहे.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(relevance_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:26.098806Z","iopub.execute_input":"2024-04-14T10:22:26.099420Z","iopub.status.idle":"2024-04-14T10:22:26.104108Z","shell.execute_reply.started":"2024-04-14T10:22:26.099383Z","shell.execute_reply":"2024-04-14T10:22:26.103228Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"4684\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(relevance_dataset_2)), relevance_dataset_2['summary']","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:28.199146Z","iopub.execute_input":"2024-04-14T10:22:28.199897Z","iopub.status.idle":"2024-04-14T10:22:28.208058Z","shell.execute_reply.started":"2024-04-14T10:22:28.199861Z","shell.execute_reply":"2024-04-14T10:22:28.207136Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"4684\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(None,\n 0       US President Donald Trump's Twitter account is...\n 1       Nearly three decades, 850 witnesses, more than...\n 2       Indian Prime Minister Narendra Modi has always...\n 3       फ्रान्समधले शेतकरी सध्या एका भलत्याच प्रश्नाने...\n 4       Unknown to most Iranians until Friday, when he...\n                               ...                        \n 4679    अमेरिकेसाठी अफगाणिस्तानातलं युद्ध हे सगळ्यांत ...\n 4680    India's government has decided to sell a contr...\n 4681    European Council President Donald Tusk has sai...\n 4682    A coronavirus vaccine developed by the Univers...\n 4683    If you are reading the headlines in the Indian...\n Name: summary, Length: 4684, dtype: object)"},"metadata":{}}]},{"cell_type":"code","source":"print(df_combined['summary'])","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:31.458993Z","iopub.execute_input":"2024-04-14T10:22:31.459718Z","iopub.status.idle":"2024-04-14T10:22:31.465758Z","shell.execute_reply.started":"2024-04-14T10:22:31.459686Z","shell.execute_reply":"2024-04-14T10:22:31.464816Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0        A feminist video-games critic has cancelled a ...\n1        Appropriate Adult, ITV1's dramatisation of the...\n2        A new report says that oil and gas producing c...\n3        Assembly member Nick Ramsay has said he has pu...\n4        Here is the full list of winners for the 2014 ...\n                               ...                        \n61111    इंग्लंडच्या सैन्यात आता गुरखा स्त्रिया असतील. ...\n61112    A teenager who killed a schoolboy after paying...\n61113    The police watchdog should be given greater po...\n61114    राष्ट्रीय किसान महासंघाने देशव्यापी शेतकरी संप...\n61115    चीनच्या सर्वकालीन महान देशप्रमुखांमध्ये दिग्गज...\nName: summary, Length: 61116, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"df_final = pd.concat([relevance_dataset, relevance_dataset_2, df_en_mr_irrelevant, df_mr_en_irrelevant, df_combined])","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:33.612074Z","iopub.execute_input":"2024-04-14T10:22:33.612812Z","iopub.status.idle":"2024-04-14T10:22:33.627179Z","shell.execute_reply.started":"2024-04-14T10:22:33.612780Z","shell.execute_reply":"2024-04-14T10:22:33.626325Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_final.columns, len(df_final)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:35.708982Z","iopub.execute_input":"2024-04-14T10:22:35.709634Z","iopub.status.idle":"2024-04-14T10:22:35.715666Z","shell.execute_reply.started":"2024-04-14T10:22:35.709602Z","shell.execute_reply":"2024-04-14T10:22:35.714701Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(Index(['summary', 'text', 'relevance', 'source_url', 'target_url'], dtype='object'),\n 90484)"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:26:10.777231Z","iopub.execute_input":"2024-04-07T05:26:10.777686Z","iopub.status.idle":"2024-04-07T05:26:11.037344Z","shell.execute_reply.started":"2024-04-07T05:26:10.777653Z","shell.execute_reply":"2024-04-07T05:26:11.036511Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f727fc220314cb7bbba61a9e477c495"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nmodel_name = \"google/muril-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:26:23.406944Z","iopub.execute_input":"2024-04-07T05:26:23.407775Z","iopub.status.idle":"2024-04-07T05:26:41.152624Z","shell.execute_reply.started":"2024-04-07T05:26:23.407740Z","shell.execute_reply":"2024-04-07T05:26:41.151654Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a039a4c26c4a43919f7de75d903e15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a56d85fc9a894b378e9977e31950ca5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"296fab344a8d494881087e89c531c50f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"912c3b6f69b247a6ac87e15f8d2d7201"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/953M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a2dea5c0c3d423dbc79403653cce828"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df_final.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:39.709052Z","iopub.execute_input":"2024-04-14T10:22:39.709436Z","iopub.status.idle":"2024-04-14T10:22:39.760906Z","shell.execute_reply.started":"2024-04-14T10:22:39.709404Z","shell.execute_reply":"2024-04-14T10:22:39.759965Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"summary           0\ntext              0\nrelevance         0\nsource_url    29368\ntarget_url    29368\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_f = df_final[['summary','text','relevance']]","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:42.020380Z","iopub.execute_input":"2024-04-14T10:22:42.021241Z","iopub.status.idle":"2024-04-14T10:22:42.036429Z","shell.execute_reply.started":"2024-04-14T10:22:42.021207Z","shell.execute_reply":"2024-04-14T10:22:42.035116Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(df_f.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:22:43.709302Z","iopub.execute_input":"2024-04-14T10:22:43.710234Z","iopub.status.idle":"2024-04-14T10:22:43.743647Z","shell.execute_reply.started":"2024-04-14T10:22:43.710198Z","shell.execute_reply":"2024-04-14T10:22:43.742561Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"summary      0\ntext         0\nrelevance    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"relevant_count = df_f[df_f['relevance'] == 1].shape[0]\nirrelevant_count = df_f[df_f['relevance'] == 0].shape[0]\n\n# Print the results\nprint(f\"Number of relevant summaries: {relevant_count}\")\nprint(f\"Number of irrelevant summaries: {irrelevant_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:24:56.068956Z","iopub.execute_input":"2024-04-14T10:24:56.069650Z","iopub.status.idle":"2024-04-14T10:24:56.088625Z","shell.execute_reply.started":"2024-04-14T10:24:56.069621Z","shell.execute_reply":"2024-04-14T10:24:56.087809Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Number of relevant summaries: 35242\nNumber of irrelevant summaries: 55242\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data, val_data = train_test_split(df_f, test_size=0.1, random_state=42)  # Adjust test_size as needed","metadata":{"execution":{"iopub.status.busy":"2024-04-08T03:58:56.166943Z","iopub.execute_input":"2024-04-08T03:58:56.167288Z","iopub.status.idle":"2024-04-08T03:58:57.346796Z","shell.execute_reply.started":"2024-04-08T03:58:56.167260Z","shell.execute_reply":"2024-04-08T03:58:57.345788Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_data.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:29:16.788585Z","iopub.execute_input":"2024-04-07T05:29:16.789409Z","iopub.status.idle":"2024-04-07T05:29:16.795652Z","shell.execute_reply.started":"2024-04-07T05:29:16.789377Z","shell.execute_reply":"2024-04-07T05:29:16.794677Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Index(['summary', 'text', 'relevance'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"!pip install datasets==2.15","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:29:19.263576Z","iopub.execute_input":"2024-04-07T05:29:19.263932Z","iopub.status.idle":"2024-04-07T05:29:34.652979Z","shell.execute_reply.started":"2024-04-07T05:29:19.263905Z","shell.execute_reply":"2024-04-07T05:29:34.651866Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Collecting datasets==2.15\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.15)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.15)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (2024.2.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.15)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.0\n    Uninstalling fsspec-2024.3.0:\n      Successfully uninstalled fsspec-2024.3.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ns3fs 2024.3.0 requires fsspec==2024.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(row):\n    return tokenizer(row['text'], row['summary'], padding='max_length', truncation=True, max_length=512)\n\n# Apply tokenization to each row of the DataFrame\ntokenized_data_train = train_data.apply(tokenize_function, axis=1)\ntokenized_data_val = val_data.apply(tokenize_function, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T11:23:47.822538Z","iopub.execute_input":"2024-04-03T11:23:47.823399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport pandas as pd\nimport torch\n\n# Assuming tokenizer is defined, for example:\n# tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n\ndef batch_tokenize_dataframe(df, tokenizer, batch_size=16):\n    # Initialize lists to hold tokenized data\n    tokenized_batches = {\n        \"input_ids\": [],\n        \"attention_mask\": [],\n        # Include \"token_type_ids\" if your model needs them\n    }\n\n    # Process dataframe in batches\n    for start_idx in range(0, len(df), batch_size):\n        end_idx = start_idx + batch_size\n        batch = df.iloc[start_idx:end_idx]\n        \n        # Tokenize batch\n        tokenized_output = tokenizer(\n            batch[\"text\"].tolist(), \n            batch[\"summary\"].tolist(), \n            padding=\"max_length\", \n            truncation=True, \n            max_length=512, \n            return_tensors=\"pt\"\n        )\n        \n        # Extend the lists\n        for key in tokenized_batches.keys():\n            tokenized_batches[key].append(tokenized_output[key])\n\n    # Concatenate all batches\n    for key in tokenized_batches.keys():\n        tokenized_batches[key] = torch.cat(tokenized_batches[key], dim=0)\n\n    # Convert to DataFrame (optional, depending on how you plan to use the tokenized data)\n    tokenized_data_df = pd.DataFrame({\n        'input_ids': tokenized_batches['input_ids'].tolist(),\n        'attention_mask': tokenized_batches['attention_mask'].tolist(),\n        # Add other fields if necessary\n    })\n\n    return tokenized_data_df\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:44:51.769079Z","iopub.execute_input":"2024-04-12T05:44:51.769716Z","iopub.status.idle":"2024-04-12T05:44:51.778473Z","shell.execute_reply.started":"2024-04-12T05:44:51.769680Z","shell.execute_reply":"2024-04-12T05:44:51.777604Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Apply the batch tokenization function to your dataframes\ntokenized_data_train_df = batch_tokenize_dataframe(train_data, tokenizer)\ntokenized_data_val_df = batch_tokenize_dataframe(val_data, tokenizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\n\nclass RelevanceDataset(Dataset):\n    def __init__(self, tokenized_data_df, original_df):\n        self.tokenized_data_df = tokenized_data_df\n        self.labels = original_df['relevance'].values  # Assuming 'relevance' is the column with labels\n\n    def __len__(self):\n        return len(self.tokenized_data_df)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_data_df.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n# Initialize the dataset\ntrain_dataset = RelevanceDataset(tokenized_data_train_df, train_data)\n\n# Example usage with DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\n# To test if your DataLoader works and inspect a batch\nfor batch in train_loader:\n    print(batch)\n    break  # Just to check the first batch","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:32:44.727886Z","iopub.execute_input":"2024-04-07T05:32:44.728874Z","iopub.status.idle":"2024-04-07T05:32:44.790724Z","shell.execute_reply.started":"2024-04-07T05:32:44.728834Z","shell.execute_reply":"2024-04-07T05:32:44.789744Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[   104,   1165, 122392,  ...,   1155,    121,    105],\n        [   104,  43465,   5100,  ...,      0,      0,      0],\n        [   104,   1129,   8056,  ...,      0,      0,      0],\n        ...,\n        [   104,  32794,  91093,  ...,  15293,    138,    105],\n        [   104,  47028,   1227,  ...,      0,      0,      0],\n        [   104,   1265,  11109,  ...,   1370,    121,    105]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n        0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0])}\n","output_type":"stream"}]},{"cell_type":"code","source":"val_dataset = RelevanceDataset(tokenized_data_val_df, val_data)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n\n# To test if your DataLoader works and inspect a batch\nfor batch in val_loader:\n    print(batch)\n    break  # Just to check the first batch","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:32:49.868871Z","iopub.execute_input":"2024-04-07T05:32:49.869223Z","iopub.status.idle":"2024-04-07T05:32:49.903028Z","shell.execute_reply.started":"2024-04-07T05:32:49.869195Z","shell.execute_reply":"2024-04-07T05:32:49.902009Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[  104,  1129, 61625,  ...,     0,     0,     0],\n        [  104, 15188,  1855,  ...,  1155,   121,   105],\n        [  104,  7056,   165,  ..., 13282,   121,   105],\n        ...,\n        [  104, 40559,  1108,  ..., 15154,   121,   105],\n        [  104,  1129,  8491,  ...,     0,     0,     0],\n        [  104, 27036, 51679,  ...,  1155,   121,   105]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1])}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Training dataset size:\", len(train_dataset))\nprint(\"Validation dataset size:\", len(val_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:32:52.719754Z","iopub.execute_input":"2024-04-07T05:32:52.720980Z","iopub.status.idle":"2024-04-07T05:32:52.727405Z","shell.execute_reply.started":"2024-04-07T05:32:52.720933Z","shell.execute_reply":"2024-04-07T05:32:52.725978Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Training dataset size: 81435\nValidation dataset size: 9049\n","output_type":"stream"}]},{"cell_type":"code","source":"model.gradient_checkpointing_enable()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:32:57.387772Z","iopub.execute_input":"2024-04-07T05:32:57.388849Z","iopub.status.idle":"2024-04-07T05:32:57.394304Z","shell.execute_reply.started":"2024-04-07T05:32:57.388815Z","shell.execute_reply":"2024-04-07T05:32:57.393275Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:32:59.227779Z","iopub.execute_input":"2024-04-07T05:32:59.228376Z","iopub.status.idle":"2024-04-07T05:32:59.664876Z","shell.execute_reply.started":"2024-04-07T05:32:59.228346Z","shell.execute_reply":"2024-04-07T05:32:59.663992Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(197285, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=f'MuRIL_relevance',\n    num_train_epochs=10,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=50,\n    save_total_limit=1,\n    save_strategy=\"epoch\",\n    evaluation_strategy=\"epoch\",\n    push_to_hub=True,\n    gradient_accumulation_steps = 32,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:33:06.845950Z","iopub.execute_input":"2024-04-07T05:33:06.846406Z","iopub.status.idle":"2024-04-07T05:33:17.487109Z","shell.execute_reply.started":"2024-04-07T05:33:06.846374Z","shell.execute_reply":"2024-04-07T05:33:17.486357Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"2024-04-07 05:33:08.574882: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-07 05:33:08.574972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-07 05:33:08.703962: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:33:20.366923Z","iopub.execute_input":"2024-04-07T05:33:20.368118Z","iopub.status.idle":"2024-04-07T05:33:22.105196Z","shell.execute_reply.started":"2024-04-07T05:33:20.368085Z","shell.execute_reply":"2024-04-07T05:33:22.104440Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train(resume_from_checkpoint=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:33:24.882085Z","iopub.execute_input":"2024-04-07T05:33:24.882445Z","iopub.status.idle":"2024-04-07T07:10:28.542174Z","shell.execute_reply.started":"2024-04-07T05:33:24.882417Z","shell.execute_reply":"2024-04-07T07:10:28.540544Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_053351-ji3jzc8m</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/btech-coep/huggingface/runs/ji3jzc8m' target=\"_blank\">pious-wave-49</a></strong> to <a href='https://wandb.ai/btech-coep/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/btech-coep/huggingface' target=\"_blank\">https://wandb.ai/btech-coep/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/btech-coep/huggingface/runs/ji3jzc8m' target=\"_blank\">https://wandb.ai/btech-coep/huggingface/runs/ji3jzc8m</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [390/390 1:33:24, Epoch 9/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>9</td>\n      <td>0.060700</td>\n      <td>0.026391</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=390, training_loss=0.003917516500521929, metrics={'train_runtime': 5803.3633, 'train_samples_per_second': 140.324, 'train_steps_per_second': 0.067, 'total_flos': 2.1051462917142528e+17, 'train_loss': 0.003917516500521929, 'epoch': 9.98})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\", tags=\"classification\")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:10:48.788534Z","iopub.execute_input":"2024-04-07T07:10:48.788913Z","iopub.status.idle":"2024-04-07T07:10:55.569512Z","shell.execute_reply.started":"2024-04-07T07:10:48.788883Z","shell.execute_reply":"2024-04-07T07:10:55.568434Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/october-sd/MuRIL_relevance/commit/db0528c7a6476e96839fb7095f7a8a6f3c1d06dc', commit_message='Training complete', commit_description='', oid='db0528c7a6476e96839fb7095f7a8a6f3c1d06dc', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport torch\n\ndef generate_relevance_score(model_path, text, summary):\n    \"\"\"\n    Generate a relevance score for a given text and summary pair using a fine-tuned MuRIL model.\n\n    Args:\n        model_path (str): Path to the fine-tuned MuRIL model.\n        text (str): The input text.\n        summary (str): The corresponding summary.\n\n    Returns:\n        float: The relevance score.\n    \"\"\"\n    # Load the tokenizer and model\n    tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n\n    # Ensure the model is in evaluation mode\n    model.eval()\n\n    # Tokenize the text and summary\n    inputs = tokenizer(text, summary, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Generate predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        probabilities = torch.softmax(logits, dim=1)\n\n    # Assuming the second column of the output represents the \"relevance\" class\n    relevance_score = probabilities[:, 1].item()  # Convert to Python float\n\n    return relevance_score\n\n# Example usage\nmodel_path = \"october-sd/MuRIL_relevance\"\ntext = relevance_dataset['text'][2]\nsummary = relevance_dataset['summary'][2]\n\nrelevance_score = generate_relevance_score(model_path, text, summary)\nprint(f\"Relevance Score: {relevance_score:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:11:01.312343Z","iopub.execute_input":"2024-04-07T07:11:01.312741Z","iopub.status.idle":"2024-04-07T07:11:22.080027Z","shell.execute_reply.started":"2024-04-07T07:11:01.312711Z","shell.execute_reply":"2024-04-07T07:11:22.078900Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3abadf9ce0ba49f5ba8508d62b46c586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/950M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659553d8f14d42b38498cb42d8e989d0"}},"metadata":{}},{"name":"stdout","text":"Relevance Score: 0.98\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\n# Ensure a GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nmodel_name = \"october-sd/MuRIL_relevance\"\ntokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\nmodel.eval()  # Put the model in evaluation mode","metadata":{"execution":{"iopub.status.busy":"2024-04-08T03:59:38.927872Z","iopub.execute_input":"2024-04-08T03:59:38.928695Z","iopub.status.idle":"2024-04-08T03:59:53.417411Z","shell.execute_reply.started":"2024-04-08T03:59:38.928662Z","shell.execute_reply":"2024-04-08T03:59:53.416479Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f7ba51d14d5456089513b7a32182efa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dee3f5cb4674617b1d1cb42810f4603"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b6c44755d79443986b922e8bab917e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4901c037e1a140ed8f9ab7fd1d583e4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"546b86b02f60421ca653b013f7512d88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/950M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6744aa143d0f499e99c19cd6979b3ce2"}},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(197285, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_data_val_df = batch_tokenize_dataframe(df_f_v, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:35.916569Z","iopub.execute_input":"2024-04-12T05:51:35.917620Z","iopub.status.idle":"2024-04-12T05:52:08.995078Z","shell.execute_reply.started":"2024-04-12T05:51:35.917578Z","shell.execute_reply":"2024-04-12T05:52:08.994284Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\n\nclass RelevanceDataset(Dataset):\n    def __init__(self, tokenized_data_df, original_df):\n        self.tokenized_data_df = tokenized_data_df\n        self.labels = original_df['relevance'].values  # Assuming 'relevance' is the column with labels\n\n    def __len__(self):\n        return len(self.tokenized_data_df)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_data_df.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:52:30.145269Z","iopub.execute_input":"2024-04-12T05:52:30.146123Z","iopub.status.idle":"2024-04-12T05:52:30.152959Z","shell.execute_reply.started":"2024-04-12T05:52:30.146093Z","shell.execute_reply":"2024-04-12T05:52:30.151811Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"val_dataset = RelevanceDataset(tokenized_data_val_df, df_f_v)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:52:46.658279Z","iopub.execute_input":"2024-04-12T05:52:46.659139Z","iopub.status.idle":"2024-04-12T05:52:46.663459Z","shell.execute_reply.started":"2024-04-12T05:52:46.659108Z","shell.execute_reply":"2024-04-12T05:52:46.662417Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:52:49.666920Z","iopub.execute_input":"2024-04-12T05:52:49.667282Z","iopub.status.idle":"2024-04-12T05:52:49.672546Z","shell.execute_reply.started":"2024-04-12T05:52:49.667255Z","shell.execute_reply":"2024-04-12T05:52:49.671371Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\n\n# Prepare lists to store outputs\ntrue_labels = []\npredictions = []\n\n# Inference\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():\n    for batch in val_loader:\n        # Move batch to GPU\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass, calculate predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        pred_labels = torch.argmax(logits, dim=1)\n\n        # Store predictions and true labels\n        predictions.extend(pred_labels.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, predictions)\nprecision = precision_score(true_labels, predictions, average='weighted')\nrecall = recall_score(true_labels, predictions, average='weighted')\nf1 = f1_score(true_labels, predictions, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-08T04:05:23.375009Z","iopub.execute_input":"2024-04-08T04:05:23.375854Z","iopub.status.idle":"2024-04-08T04:08:03.014262Z","shell.execute_reply.started":"2024-04-08T04:05:23.375819Z","shell.execute_reply":"2024-04-08T04:08:03.013253Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Accuracy: 0.9956\nPrecision: 0.9956\nRecall: 0.9956\nF1 Score: 0.9956\n","output_type":"stream"}]},{"cell_type":"code","source":"# Label relevant pairs with '1'\ndf_en_test['relevance'] = 1\ndf_val_cs_mar['relevance'] = 1\n# Shuffle texts within each DataFrame to create irrelevant pairs\n# Reset index before sampling to ensure alignment\ndf_en_reset = df_en_test.reset_index(drop=True)\ndf_mr_reset = df_val_cs_mar.reset_index(drop=True)\n\ndf_en_irrelevant = df_en_reset.copy().assign(text=df_en_reset['text'].sample(frac=1).reset_index(drop=True), relevance=0)\ndf_mr_irrelevant = df_mr_reset.copy().assign(text=df_mr_reset['text'].sample(frac=1).reset_index(drop=True), relevance=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:48:32.113159Z","iopub.execute_input":"2024-04-12T05:48:32.113899Z","iopub.status.idle":"2024-04-12T05:48:32.126338Z","shell.execute_reply.started":"2024-04-12T05:48:32.113864Z","shell.execute_reply":"2024-04-12T05:48:32.125399Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Combine relevant and irrelevant pairs for each language\ndf_en_combined = pd.concat([df_en_test, df_en_irrelevant])\ndf_mr_combined = pd.concat([df_val_cs_mar, df_mr_irrelevant])\n\n# Combine English and Marathi data\ndf_combined = pd.concat([df_en_combined, df_mr_combined], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:48:33.810944Z","iopub.execute_input":"2024-04-12T05:48:33.811628Z","iopub.status.idle":"2024-04-12T05:48:33.820598Z","shell.execute_reply.started":"2024-04-12T05:48:33.811593Z","shell.execute_reply":"2024-04-12T05:48:33.819665Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Shuffle the combined DataFrame to ensure a random distribution of data\ndf_combined = df_combined.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:48:36.171274Z","iopub.execute_input":"2024-04-12T05:48:36.172137Z","iopub.status.idle":"2024-04-12T05:48:36.185652Z","shell.execute_reply.started":"2024-04-12T05:48:36.172105Z","shell.execute_reply":"2024-04-12T05:48:36.184565Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"len(df_combined)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:48:51.228799Z","iopub.execute_input":"2024-04-12T05:48:51.229145Z","iopub.status.idle":"2024-04-12T05:48:51.235537Z","shell.execute_reply.started":"2024-04-12T05:48:51.229119Z","shell.execute_reply":"2024-04-12T05:48:51.234608Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"12508"},"metadata":{}}]},{"cell_type":"code","source":"print(df_combined.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:48:54.729658Z","iopub.execute_input":"2024-04-12T05:48:54.730535Z","iopub.status.idle":"2024-04-12T05:48:54.743349Z","shell.execute_reply.started":"2024-04-12T05:48:54.730503Z","shell.execute_reply":"2024-04-12T05:48:54.742427Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"source_url    0\ntarget_url    0\ntext          0\nsummary       0\nrelevance     0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sampling 10,000 rows from each DataFrame\ndf_en_sample = df_en_test.sample(n=1000, random_state=42)  # English DataFrame\ndf_mr_sample = df_val_cs_mar.sample(n=1000, random_state=42)  # Marathi DataFrame","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:03.896994Z","iopub.execute_input":"2024-04-12T05:51:03.897399Z","iopub.status.idle":"2024-04-12T05:51:03.906925Z","shell.execute_reply.started":"2024-04-12T05:51:03.897366Z","shell.execute_reply":"2024-04-12T05:51:03.905906Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Reset index to align the samples\ndf_en_sample.reset_index(drop=True, inplace=True)\ndf_mr_sample.reset_index(drop=True, inplace=True)\n\n# Create cross-lingual irrelevant pairs\n# English text with Marathi summary\ndf_en_mr_irrelevant = pd.DataFrame({\n    'text': df_en_sample['text'],\n    'summary': df_mr_sample['summary'],\n    'relevance': 0  # Mark as irrelevant\n})\n\n# Marathi text with English summary\ndf_mr_en_irrelevant = pd.DataFrame({\n    'text': df_mr_sample['text'],\n    'summary': df_en_sample['summary'],\n    'relevance': 0  # Mark as irrelevant\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:05.881837Z","iopub.execute_input":"2024-04-12T05:51:05.882190Z","iopub.status.idle":"2024-04-12T05:51:05.889827Z","shell.execute_reply.started":"2024-04-12T05:51:05.882161Z","shell.execute_reply":"2024-04-12T05:51:05.888923Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_final_validation = pd.concat([relevance_dataset_2, df_en_mr_irrelevant, df_mr_en_irrelevant, df_combined])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:07.951456Z","iopub.execute_input":"2024-04-12T05:51:07.951806Z","iopub.status.idle":"2024-04-12T05:51:07.960982Z","shell.execute_reply.started":"2024-04-12T05:51:07.951778Z","shell.execute_reply":"2024-04-12T05:51:07.959938Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"len(df_final_validation)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:09.503800Z","iopub.execute_input":"2024-04-12T05:51:09.504411Z","iopub.status.idle":"2024-04-12T05:51:09.510491Z","shell.execute_reply.started":"2024-04-12T05:51:09.504375Z","shell.execute_reply":"2024-04-12T05:51:09.509286Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"19192"},"metadata":{}}]},{"cell_type":"code","source":"df_final_validation.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:12.513320Z","iopub.execute_input":"2024-04-12T05:51:12.513682Z","iopub.status.idle":"2024-04-12T05:51:12.519826Z","shell.execute_reply.started":"2024-04-12T05:51:12.513654Z","shell.execute_reply":"2024-04-12T05:51:12.518814Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Index(['summary', 'text', 'relevance', 'source_url', 'target_url'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\n# Ensure a GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nmodel_name = \"october-sd/MuRIL_relevance\"\ntokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\nmodel.eval()  # Put the model in evaluation mode","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:40:20.057181Z","iopub.execute_input":"2024-04-12T05:40:20.058126Z","iopub.status.idle":"2024-04-12T05:44:51.767076Z","shell.execute_reply.started":"2024-04-12T05:40:20.058092Z","shell.execute_reply":"2024-04-12T05:44:51.766073Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0922d1d4131041d4984b0c469a917905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b8b1e87a8fb4d01b891065ccf3f3363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dac10af4ca641fb92790d1400d41c30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca8dd8958ae44f20b6078d58b1bc0a9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec2a171e60324e319a43696c07d854c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/950M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7be713c8cff486999e9693ac02491ff"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(197285, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"df_f_v = df_final_validation[['summary','text','relevance']]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:16.261903Z","iopub.execute_input":"2024-04-12T05:51:16.262265Z","iopub.status.idle":"2024-04-12T05:51:16.269130Z","shell.execute_reply.started":"2024-04-12T05:51:16.262235Z","shell.execute_reply":"2024-04-12T05:51:16.268192Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(df_f_v.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:51:22.281267Z","iopub.execute_input":"2024-04-12T05:51:22.281638Z","iopub.status.idle":"2024-04-12T05:51:22.293568Z","shell.execute_reply.started":"2024-04-12T05:51:22.281610Z","shell.execute_reply":"2024-04-12T05:51:22.292556Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"summary      0\ntext         0\nrelevance    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(df_f_v))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:52:15.405383Z","iopub.execute_input":"2024-04-12T05:52:15.406243Z","iopub.status.idle":"2024-04-12T05:52:15.410984Z","shell.execute_reply.started":"2024-04-12T05:52:15.406210Z","shell.execute_reply":"2024-04-12T05:52:15.410069Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"19192\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\n\n# Prepare lists to store outputs\ntrue_labels = []\npredictions = []\n\n# Inference\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():\n    for batch in val_loader:\n        # Move batch to GPU\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass, calculate predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        pred_labels = torch.argmax(logits, dim=1)\n\n        # Store predictions and true labels\n        predictions.extend(pred_labels.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, predictions)\nprecision = precision_score(true_labels, predictions, average='weighted')\nrecall = recall_score(true_labels, predictions, average='weighted')\nf1 = f1_score(true_labels, predictions, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:53:06.858604Z","iopub.execute_input":"2024-04-12T05:53:06.859298Z","iopub.status.idle":"2024-04-12T05:58:46.506822Z","shell.execute_reply.started":"2024-04-12T05:53:06.859267Z","shell.execute_reply":"2024-04-12T05:58:46.505734Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Accuracy: 0.9924\nPrecision: 0.9924\nRecall: 0.9924\nF1 Score: 0.9924\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\n\n# Prepare lists to store outputs\ntrue_labels = []\npredictions = []\n\n# Inference\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():\n    for batch in val_loader:\n        # Move batch to GPU\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass, calculate predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        pred_labels = torch.softmax(logits, dim=1)\n\n        # Store predictions and true labels\n        predictions.extend(pred_labels.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, predictions)\nprecision = precision_score(true_labels, predictions, average='weighted')\nrecall = recall_score(true_labels, predictions, average='weighted')\nf1 = f1_score(true_labels, predictions, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:07:29.289066Z","iopub.execute_input":"2024-04-12T06:07:29.289543Z","iopub.status.idle":"2024-04-12T06:13:08.779552Z","shell.execute_reply.started":"2024-04-12T06:07:29.289499Z","shell.execute_reply":"2024-04-12T06:13:08.778195Z"},"trusted":true},"execution_count":51,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         true_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(true_labels, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(true_labels, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"],"ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and continuous-multioutput targets","output_type":"error"}]},{"cell_type":"code","source":"print(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(logits)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:01:17.092200Z","iopub.execute_input":"2024-04-12T06:01:17.092496Z","iopub.status.idle":"2024-04-12T06:01:17.103483Z","shell.execute_reply.started":"2024-04-12T06:01:17.092471Z","shell.execute_reply":"2024-04-12T06:01:17.102415Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"tensor([[ 2.3244, -2.3004],\n        [ 2.3241, -2.3000],\n        [-2.0941,  2.0769],\n        [ 2.3247, -2.3010],\n        [ 2.3235, -2.2999],\n        [-2.0944,  2.0775],\n        [ 2.3231, -2.2985],\n        [ 2.3248, -2.3011],\n        [ 2.3228, -2.2984],\n        [-2.0939,  2.0773],\n        [-2.0938,  2.0771],\n        [ 2.3238, -2.2999],\n        [ 2.3246, -2.3002],\n        [ 2.2837, -2.2590],\n        [-2.0939,  2.0773],\n        [-2.0940,  2.0771],\n        [-2.0949,  2.0780],\n        [-2.0941,  2.0771],\n        [ 2.3224, -2.2975],\n        [-2.0946,  2.0778],\n        [ 2.3247, -2.3010],\n        [ 2.1408, -2.1177],\n        [ 2.3233, -2.2993],\n        [-2.0949,  2.0779],\n        [-2.0942,  2.0774],\n        [ 2.3219, -2.2976],\n        [ 2.3240, -2.3001],\n        [-2.0948,  2.0778],\n        [-2.0886,  2.0713],\n        [-2.0946,  2.0778],\n        [-2.0882,  2.0710],\n        [ 2.3252, -2.3013],\n        [ 2.3235, -2.2995],\n        [-2.0941,  2.0776],\n        [-2.0944,  2.0775],\n        [-2.0946,  2.0776],\n        [-2.0948,  2.0779],\n        [-2.0943,  2.0774],\n        [ 2.3237, -2.2996],\n        [-2.0936,  2.0770],\n        [-2.0946,  2.0776],\n        [-2.0944,  2.0777],\n        [-2.0948,  2.0779],\n        [ 2.3232, -2.2992],\n        [ 2.3235, -2.2999],\n        [-2.0947,  2.0778],\n        [ 2.3247, -2.3002],\n        [-2.0939,  2.0766],\n        [ 2.3198, -2.2960],\n        [ 2.3215, -2.2978],\n        [ 2.3178, -2.2928],\n        [ 2.3246, -2.3005],\n        [ 2.3219, -2.2977],\n        [-2.0939,  2.0773],\n        [-2.0944,  2.0775],\n        [-2.0936,  2.0769]], device='cuda:0')\n","output_type":"stream"}]}]}