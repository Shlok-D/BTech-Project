{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7815907,"sourceType":"datasetVersion","datasetId":4572300}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-15T18:35:45.207117Z","iopub.execute_input":"2024-03-15T18:35:45.207828Z","iopub.status.idle":"2024-03-15T18:35:45.672466Z","shell.execute_reply.started":"2024-03-15T18:35:45.207798Z","shell.execute_reply":"2024-03-15T18:35:45.671581Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/english-summarization-dataset/test_final_eng.csv\n/kaggle/input/english-summarization-dataset/val_final_eng.csv\n/kaggle/input/english-summarization-dataset/train_final_eng.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf_train_final_mar=pd.read_csv(\"/kaggle/input/english-summarization-dataset/train_final_eng.csv\")\ndf_train_final_mar['text'][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:35:48.808667Z","iopub.execute_input":"2024-03-15T18:35:48.809183Z","iopub.status.idle":"2024-03-15T18:35:52.982445Z","shell.execute_reply.started":"2024-03-15T18:35:48.809145Z","shell.execute_reply":"2024-03-15T18:35:52.981455Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'The chain said the cuts were largely due to its integration of Argos - which it bought in 2016 - into the business. It said the move represented the \"finalising\" of new management structures and the merging of its store support centre teams and were part of cost savings already announced. Since March 2019, Sainsbury\\'s has axed one in five senior leadership roles. Last year, it also announced an overhaul of the business aimed at saving £500m, including plans to move up to 70 Argos shops within its business. Sainsbury\\'s employs 178,000 people in total. In Tuesday\\'s update, it refused to say how many management roles in total would be axed. Cost cutting Sainsbury\\'s chief executive Mike Coupe said: \"We have to adapt to continue to meet the needs of our customers now and in the future and, while change can be hard, it\\'s also necessary.\" A spokeswoman said the planned management cuts were part of efforts by the supermarket to try to avoid duplication of roles between Sainsbury\\'s and Argos. Sainsbury\\'s outlined a new strategy in September after its failed Asda merger bid. The plan focused on cost cutting, paying off debt, more technology and further integration with Argos, which it purchased in 2016. Earlier this month Sainsbury\\'s said Christmas sales had fallen despite solid grocery sales after people bought fewer toys. Retail analyst Richard Hyman said the job cuts could have an adverse impact on how the business operates. \"Retailing is a people business,\" he said. \"Stripping out people without any impact on the business [and the customer experience] is difficult.\" He said retail was a tough market which was forcing some chains to prioritise lowering costs over investing, adding that \"retail winners\" are those prepared to make investments to improve revenue.'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf_val_final_mar=pd.read_csv(\"/kaggle/input/english-summarization-dataset/val_final_eng.csv\")\ndf_val_final_mar['text'][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:35:55.745759Z","iopub.execute_input":"2024-03-15T18:35:55.746116Z","iopub.status.idle":"2024-03-15T18:35:56.047577Z","shell.execute_reply.started":"2024-03-15T18:35:55.746086Z","shell.execute_reply":"2024-03-15T18:35:56.046703Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'Sterling dipped 1.1% to $1.2242 and €1.1004 respectively. The currency could fall further, according to analysts at ING Group, as traders appear to have been betting on a last-minute deal being reached. Many business lobby groups have asked that no-deal be withdrawn as an option to keep investment flowing into the UK. The pound dropped after \"the events over the weekend, where the current stance of the new government became clear\", said Petr Krpata, a currency strategist at ING Group. Michael Gove, who is in charge of planning for no-deal, has said the UK government is currently \"working on the assumption\" of that very outcome. He said his team still aimed to come to an agreement with Brussels, but writing in the Sunday Times, he added: \"No deal is now a very real prospect.\" Mr Krpata says ING Group\\'s assumption is that an early election will take place and that the pound will sink as low as €1.05 and $1.18. The last low for sterling was $1.2049, reached in January 2017. The record low was $1.0545 from March 1985, just before G7 powers acted to constrain a particularly strong US currency. Sterling suffered today, at the worst possible time for holidaymakers, as the probability of leaving the EU without a deal rises. It dropped to its lowest level versus the dollar since the Article 50 process began in March 2017, just about staying above $1.22. It reached a two-year low versus the euro of below €1.10. The weakness is now broad based - there was also a fall against the Yen. It is now a trend, down between 6% and 9% against the major currencies since the beginning of May. This will mean rising consumer prices. The rough rule of thumb would see this 6% trade-weighted fall add about 1 percentage point to inflation, enough to complicate the decisions of the Bank of England over interest rates. In theory, a lower pound helps some exporters and, for example, the domestic UK tourism industry. But so much of our manufacturing base needs to import components in order to make those exports, that this effect has not been strong in the years following the significant pound devaluation after the 2016 Brexit vote. Currencies fluctuate, of course, but the path for the pound has been firmly down, as markets start to calculate that the odds on No Deal are far closer to evens than, as the PM has suggested, \"a million to one\". The pound\\'s performance against the dollar During a visit to Scotland, Mr Johnson said the existing withdrawal agreement negotiated with European leaders was \"dead\" and had \"got to go\". EU member nations have said renegotiating the deal is not an option. Today\\'s prices mean even fewer euros and dollars at the bureau de change for holidaymakers. At the Post Office, £1 buys €1.0817 or $1.2041, according to its website. The pound\\'s performance against the euro Separately, UK government debt prices gained as traders bet on a higher chance that interest rates will be cut. The country\\'s 10-year bonds, considered the benchmark, are changing hands for a price that yields as low as 0.627%, the lowest in nearly three years. This implies that the cost of borrowing for the government has fallen.'"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:35:59.084390Z","iopub.execute_input":"2024-03-15T18:35:59.084728Z","iopub.status.idle":"2024-03-15T18:35:59.108987Z","shell.execute_reply.started":"2024-03-15T18:35:59.084699Z","shell.execute_reply":"2024-03-15T18:35:59.108184Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1a5ce7189aa493da905e80eb290c16e"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install datasets==2.15","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:15.318535Z","iopub.execute_input":"2024-03-15T18:36:15.319147Z","iopub.status.idle":"2024-03-15T18:36:31.467815Z","shell.execute_reply.started":"2024-03-15T18:36:15.319116Z","shell.execute_reply":"2024-03-15T18:36:31.466604Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting datasets==2.15\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.15)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.15)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (2024.2.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.15)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.2.0\n    Uninstalling fsspec-2024.2.0:\n      Successfully uninstalled fsspec-2024.2.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ns3fs 2024.2.0 requires fsspec==2024.2.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom transformers import pipeline\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:31.470005Z","iopub.execute_input":"2024-03-15T18:36:31.470332Z","iopub.status.idle":"2024-03-15T18:36:44.311166Z","shell.execute_reply.started":"2024-03-15T18:36:31.470303Z","shell.execute_reply":"2024-03-15T18:36:44.310304Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-03-15 18:36:33.297278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-15 18:36:33.297397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-15 18:36:33.443351: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# pipe = pipeline(\"summarization\", model=\"facebook/bart-large-xsum\")","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:44.312270Z","iopub.execute_input":"2024-03-15T18:36:44.312889Z","iopub.status.idle":"2024-03-15T18:36:44.317095Z","shell.execute_reply.started":"2024-03-15T18:36:44.312862Z","shell.execute_reply":"2024-03-15T18:36:44.316134Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# pipe_out = pipe(df_train_final_mar[\"text\"][0])\n# print(\"Summary:\")\n# print(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:44.319239Z","iopub.execute_input":"2024-03-15T18:36:44.319514Z","iopub.status.idle":"2024-03-15T18:36:44.328129Z","shell.execute_reply.started":"2024-03-15T18:36:44.319490Z","shell.execute_reply":"2024-03-15T18:36:44.327360Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_ckpt = \"facebook/bart-large-xsum\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:44.329178Z","iopub.execute_input":"2024-03-15T18:36:44.329487Z","iopub.status.idle":"2024-03-15T18:36:54.897309Z","shell.execute_reply.started":"2024-03-15T18:36:44.329462Z","shell.execute_reply":"2024-03-15T18:36:54.896502Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877044e2e5a24070be10b6504f88f7d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e41f56369268458c89dba3803cc47bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0726c511bb4d4765949a8fb6d578b192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b493b06c5982470084660637f1d52384"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6e0413aa2b482db98d11d34914eb19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfec23c6a4724c17bd14432b82ecdbf7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/309 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bdc168c0c43461e945a83480560761f"}},"metadata":{}}]},{"cell_type":"code","source":"# d_len = [len(tokenizer.encode(s)) for s in dataset[\"text\"]]\n# s_len = [len(tokenizer.encode(s)) for s in dataset[\"summary\"]]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:54.898395Z","iopub.execute_input":"2024-03-15T18:36:54.898703Z","iopub.status.idle":"2024-03-15T18:36:54.902735Z","shell.execute_reply.started":"2024-03-15T18:36:54.898678Z","shell.execute_reply":"2024-03-15T18:36:54.901851Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# fig, axes = plt.subplots(1, 2, sharey=True)\n# axes[0].hist(d_len, bins=20)\n# axes[0].set_title(\"Text Token Length\")\n# axes[1].hist(s_len, bins=20)\n# axes[1].set_title(\"Summary Token Length\")\n# plt.tight_layout()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:54.903810Z","iopub.execute_input":"2024-03-15T18:36:54.904081Z","iopub.status.idle":"2024-03-15T18:36:54.913758Z","shell.execute_reply.started":"2024-03-15T18:36:54.904058Z","shell.execute_reply":"2024-03-15T18:36:54.912919Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(df_train_final_mar)\nlen(dataset)\nprint(dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:54.914752Z","iopub.execute_input":"2024-03-15T18:36:54.915047Z","iopub.status.idle":"2024-03-15T18:36:55.770615Z","shell.execute_reply.started":"2024-03-15T18:36:54.915023Z","shell.execute_reply":"2024-03-15T18:36:55.769559Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'text': 'The chain said the cuts were largely due to its integration of Argos - which it bought in 2016 - into the business. It said the move represented the \"finalising\" of new management structures and the merging of its store support centre teams and were part of cost savings already announced. Since March 2019, Sainsbury\\'s has axed one in five senior leadership roles. Last year, it also announced an overhaul of the business aimed at saving £500m, including plans to move up to 70 Argos shops within its business. Sainsbury\\'s employs 178,000 people in total. In Tuesday\\'s update, it refused to say how many management roles in total would be axed. Cost cutting Sainsbury\\'s chief executive Mike Coupe said: \"We have to adapt to continue to meet the needs of our customers now and in the future and, while change can be hard, it\\'s also necessary.\" A spokeswoman said the planned management cuts were part of efforts by the supermarket to try to avoid duplication of roles between Sainsbury\\'s and Argos. Sainsbury\\'s outlined a new strategy in September after its failed Asda merger bid. The plan focused on cost cutting, paying off debt, more technology and further integration with Argos, which it purchased in 2016. Earlier this month Sainsbury\\'s said Christmas sales had fallen despite solid grocery sales after people bought fewer toys. Retail analyst Richard Hyman said the job cuts could have an adverse impact on how the business operates. \"Retailing is a people business,\" he said. \"Stripping out people without any impact on the business [and the customer experience] is difficult.\" He said retail was a tough market which was forcing some chains to prioritise lowering costs over investing, adding that \"retail winners\" are those prepared to make investments to improve revenue.', 'summary': \"Sainsbury's has announced plans to cut hundreds of management roles in a fresh round of job cuts at the supermarket.\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_2 = Dataset.from_pandas(df_val_final_mar)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:55.771748Z","iopub.execute_input":"2024-03-15T18:36:55.772329Z","iopub.status.idle":"2024-03-15T18:36:55.821390Z","shell.execute_reply.started":"2024-03-15T18:36:55.772303Z","shell.execute_reply":"2024-03-15T18:36:55.820355Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer.as_target_tokenizer()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:55.825921Z","iopub.execute_input":"2024-03-15T18:36:55.826732Z","iopub.status.idle":"2024-03-15T18:36:55.832545Z","shell.execute_reply.started":"2024-03-15T18:36:55.826702Z","shell.execute_reply":"2024-03-15T18:36:55.831648Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<contextlib._GeneratorContextManager at 0x7ba9d6488d90>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:55.833649Z","iopub.execute_input":"2024-03-15T18:36:55.833974Z","iopub.status.idle":"2024-03-15T18:36:56.473779Z","shell.execute_reply.started":"2024-03-15T18:36:55.833926Z","shell.execute_reply":"2024-03-15T18:36:56.472832Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50264, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 128\n\ndef preprocess_function(examples):\n    inputs = [ex for ex in examples[\"text\"]]\n    targets = [ex for ex in examples[\"summary\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n    # Setup the tokenizer for targets\n    # no need this line \n    # with tokenizer.as_target_tokenizer():\n    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:56.474934Z","iopub.execute_input":"2024-03-15T18:36:56.475237Z","iopub.status.idle":"2024-03-15T18:36:56.481366Z","shell.execute_reply.started":"2024-03-15T18:36:56.475212Z","shell.execute_reply":"2024-03-15T18:36:56.480452Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = dataset.map(preprocess_function, batched=True)\ntokenized_test_set = dataset_2.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:36:56.482541Z","iopub.execute_input":"2024-03-15T18:36:56.482835Z","iopub.status.idle":"2024-03-15T18:38:12.589964Z","shell.execute_reply.started":"2024-03-15T18:36:56.482812Z","shell.execute_reply":"2024-03-15T18:38:12.589021Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/65000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4567d94ad2244d04a6d39069dbb79f95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da399fc690884b04932679adf6d1a2be"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = {'train': dataset, 'val':dataset_2}","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.591021Z","iopub.execute_input":"2024-03-15T18:38:12.591313Z","iopub.status.idle":"2024-03-15T18:38:12.595417Z","shell.execute_reply.started":"2024-03-15T18:38:12.591288Z","shell.execute_reply":"2024-03-15T18:38:12.594492Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"columns = [\"input_ids\", \"labels\", \"attention_mask\"]\ntokenized_datasets.set_format(type=\"torch\", columns=columns)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.596659Z","iopub.execute_input":"2024-03-15T18:38:12.597258Z","iopub.status.idle":"2024-03-15T18:38:12.607461Z","shell.execute_reply.started":"2024-03-15T18:38:12.597226Z","shell.execute_reply":"2024-03-15T18:38:12.606556Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(dataset[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.608565Z","iopub.execute_input":"2024-03-15T18:38:12.608826Z","iopub.status.idle":"2024-03-15T18:38:12.620762Z","shell.execute_reply.started":"2024-03-15T18:38:12.608804Z","shell.execute_reply":"2024-03-15T18:38:12.619849Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"65000"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_test_set.set_format(type=\"torch\", columns=columns)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.621898Z","iopub.execute_input":"2024-03-15T18:38:12.622266Z","iopub.status.idle":"2024-03-15T18:38:12.630595Z","shell.execute_reply.started":"2024-03-15T18:38:12.622230Z","shell.execute_reply":"2024-03-15T18:38:12.629679Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model.gradient_checkpointing_enable()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.631926Z","iopub.execute_input":"2024-03-15T18:38:12.632301Z","iopub.status.idle":"2024-03-15T18:38:12.645273Z","shell.execute_reply.started":"2024-03-15T18:38:12.632269Z","shell.execute_reply":"2024-03-15T18:38:12.644401Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.646229Z","iopub.execute_input":"2024-03-15T18:38:12.646481Z","iopub.status.idle":"2024-03-15T18:38:12.655017Z","shell.execute_reply.started":"2024-03-15T18:38:12.646459Z","shell.execute_reply":"2024-03-15T18:38:12.654163Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\nbatch_size = 8\nnum_train_epochs = 2\n# Show the training loss with every epoch\nlogging_steps = len(dataset[\"train\"]) // batch_size\nmodel_name = model_ckpt.split(\"/\")[-1]\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=f\"{model_name}-finetuned-mr-sum\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=5e-6,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    fp16=True,\n    save_total_limit=1,\n    save_strategy=\"epoch\",\n    predict_with_generate=True,\n    num_train_epochs=num_train_epochs,\n    logging_steps=logging_steps,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.656079Z","iopub.execute_input":"2024-03-15T18:38:12.656340Z","iopub.status.idle":"2024-03-15T18:38:12.674380Z","shell.execute_reply.started":"2024-03-15T18:38:12.656311Z","shell.execute_reply":"2024-03-15T18:38:12.673435Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns(\n    dataset[\"train\"].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.675655Z","iopub.execute_input":"2024-03-15T18:38:12.676288Z","iopub.status.idle":"2024-03-15T18:38:12.682711Z","shell.execute_reply.started":"2024-03-15T18:38:12.676262Z","shell.execute_reply":"2024-03-15T18:38:12.681836Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tokenized_test_set = tokenized_test_set.remove_columns(\n    dataset[\"val\"].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.684174Z","iopub.execute_input":"2024-03-15T18:38:12.684483Z","iopub.status.idle":"2024-03-15T18:38:12.691636Z","shell.execute_reply.started":"2024-03-15T18:38:12.684457Z","shell.execute_reply":"2024-03-15T18:38:12.690831Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets,\n    eval_dataset=tokenized_test_set,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:12.692879Z","iopub.execute_input":"2024-03-15T18:38:12.693196Z","iopub.status.idle":"2024-03-15T18:38:13.711269Z","shell.execute_reply.started":"2024-03-15T18:38:12.693172Z","shell.execute_reply":"2024-03-15T18:38:13.710276Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:13.712692Z","iopub.execute_input":"2024-03-15T18:38:13.713071Z","iopub.status.idle":"2024-03-16T05:13:46.387956Z","shell.execute_reply.started":"2024-03-15T18:38:13.713036Z","shell.execute_reply":"2024-03-16T05:13:46.386977Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240315_183837-1u02e3u8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ssvbtech/huggingface/runs/1u02e3u8' target=\"_blank\">daily-tree-4</a></strong> to <a href='https://wandb.ai/ssvbtech/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ssvbtech/huggingface' target=\"_blank\">https://wandb.ai/ssvbtech/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ssvbtech/huggingface/runs/1u02e3u8' target=\"_blank\">https://wandb.ai/ssvbtech/huggingface/runs/1u02e3u8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16250' max='16250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16250/16250 10:33:44, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.600100</td>\n      <td>1.633071</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.444400</td>\n      <td>1.633434</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=16250, training_loss=1.522247235576923, metrics={'train_runtime': 38082.6843, 'train_samples_per_second': 3.414, 'train_steps_per_second': 0.427, 'total_flos': 2.6178897867689165e+17, 'train_loss': 1.522247235576923, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:17:24.080360Z","iopub.execute_input":"2024-03-16T05:17:24.080747Z","iopub.status.idle":"2024-03-16T05:17:33.369049Z","shell.execute_reply.started":"2024-03-16T05:17:24.080716Z","shell.execute_reply":"2024-03-16T05:17:33.368014Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/october-sd/bart-large-xsum-finetuned-mr-sum/commit/c7b68b1cf917e33dd2edbf41f4e983626f705334', commit_message='Training complete', commit_description='', oid='c7b68b1cf917e33dd2edbf41f4e983626f705334', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}