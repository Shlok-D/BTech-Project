{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7927028,"sourceType":"datasetVersion","datasetId":4524856}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Path to the JSON Lines file\nfile_path = [\"/kaggle/input/marathi-summarization-dataset/marathi-marathi_test.jsonl\", \"/kaggle/input/marathi-summarization-dataset/marathi-marathi_train.jsonl\",\"/kaggle/input/marathi-summarization-dataset/marathi-marathi_val.jsonl\"]\n\n\n# Initialize an empty list to hold the JSON objects\ndata = []\n\n# Open the file and read line by line\nfor i in range(3):\n    data.append([])\n    with open(file_path[i], 'r', encoding='utf-8') as file:\n        for line in file:\n            # Parse each line as a JSON object and append to the list\n            data[i].append(json.loads(line))\n    \n\n# Convert the list of JSON objects into a DataFrame\ndf_mr = pd.DataFrame(data[1])\ndf_test_cs_mar = pd.DataFrame(data[0])\ndf_val_cs_mar = pd.DataFrame(data[2])\n\n# Display the first few rows of the DataFrame to check if it's loaded correctly\nprint(len(df_mr))\nprint(len(df_test_cs_mar))\nprint(len(df_val_cs_mar))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-10T02:39:43.609640Z","iopub.execute_input":"2024-04-10T02:39:43.609928Z","iopub.status.idle":"2024-04-10T02:39:47.271494Z","shell.execute_reply.started":"2024-04-10T02:39:43.609904Z","shell.execute_reply":"2024-04-10T02:39:47.270570Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"10558\n1188\n1254\n","output_type":"stream"}]},{"cell_type":"code","source":"df_mr_train = pd.concat([df_mr, df_test_cs_mar],ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:40:17.184739Z","iopub.execute_input":"2024-04-10T02:40:17.185449Z","iopub.status.idle":"2024-04-10T02:40:17.191109Z","shell.execute_reply.started":"2024-04-10T02:40:17.185416Z","shell.execute_reply":"2024-04-10T02:40:17.190224Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"len(df_mr_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:40:19.092137Z","iopub.execute_input":"2024-04-10T02:40:19.092873Z","iopub.status.idle":"2024-04-10T02:40:19.098991Z","shell.execute_reply.started":"2024-04-10T02:40:19.092838Z","shell.execute_reply":"2024-04-10T02:40:19.098112Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"11746"},"metadata":{}}]},{"cell_type":"code","source":"df_mr_train['summary'][1]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:40:21.400277Z","iopub.execute_input":"2024-04-10T02:40:21.400821Z","iopub.status.idle":"2024-04-10T02:40:21.409092Z","shell.execute_reply.started":"2024-04-10T02:40:21.400794Z","shell.execute_reply":"2024-04-10T02:40:21.408256Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'रोजीरोटीसाठी महाराष्ट्रात काम करणाऱ्या तामिळनाडूतील थिरुवरुर आणि नागापट्टणम इथल्या सात तरुणांनी तब्बल हजार किलोमीटरचं अंतर पायी कापत गाव गाठलं आहे.'"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:40:37.625130Z","iopub.execute_input":"2024-04-10T02:40:37.625964Z","iopub.status.idle":"2024-04-10T02:40:37.888459Z","shell.execute_reply.started":"2024-04-10T02:40:37.625931Z","shell.execute_reply":"2024-04-10T02:40:37.887566Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc1d2d2634334e168d17b12b04432f5a"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"ai4bharat/IndicBART\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint,do_lower_case=False, use_fast=False, keep_accents=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:40:44.586259Z","iopub.execute_input":"2024-04-10T02:40:44.587253Z","iopub.status.idle":"2024-04-10T02:40:52.477574Z","shell.execute_reply.started":"2024-04-10T02:40:44.587220Z","shell.execute_reply":"2024-04-10T02:40:52.476627Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c413e151b54e608987840ff04a6e1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/832 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8517956a0f8477c88899bad4099d5af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.90M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed5b328801c45f2ab8b3d237a4c14df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/221 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df3f38a0f8d444439869eed2ddb3204c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/398 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c604411b2124c678a44095e3408ca1e"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tokenizer(\"I loved reading the Hunger Games!\")\ninputs","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:01.918194Z","iopub.execute_input":"2024-04-10T02:41:01.919124Z","iopub.status.idle":"2024-04-10T02:41:01.925401Z","shell.execute_reply.started":"2024-04-10T02:41:01.919066Z","shell.execute_reply":"2024-04-10T02:41:01.924510Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [2, 466, 50171, 30053, 22, 2371, 10777, 536, 30305, 194, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.convert_ids_to_tokens(inputs.input_ids)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:03.863230Z","iopub.execute_input":"2024-04-10T02:41:03.864102Z","iopub.status.idle":"2024-04-10T02:41:03.870216Z","shell.execute_reply.started":"2024-04-10T02:41:03.864049Z","shell.execute_reply":"2024-04-10T02:41:03.869371Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n '▁I',\n '▁loved',\n '▁reading',\n '▁the',\n '▁H',\n 'ung',\n 'er',\n '▁Games',\n '!',\n '[SEP]']"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.as_target_tokenizer()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:06.590479Z","iopub.execute_input":"2024-04-10T02:41:06.591166Z","iopub.status.idle":"2024-04-10T02:41:06.596708Z","shell.execute_reply.started":"2024-04-10T02:41:06.591136Z","shell.execute_reply":"2024-04-10T02:41:06.595777Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<contextlib._GeneratorContextManager at 0x7fe73cd81750>"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 128\n\ndef preprocess_function(examples):\n    inputs = [ex for ex in examples[\"text\"]]\n    targets = [ex for ex in examples[\"summary\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n    # Setup the tokenizer for targets\n    # no need this line \n    # with tokenizer.as_target_tokenizer():\n    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:08.975165Z","iopub.execute_input":"2024-04-10T02:41:08.975561Z","iopub.status.idle":"2024-04-10T02:41:08.981890Z","shell.execute_reply.started":"2024-04-10T02:41:08.975531Z","shell.execute_reply":"2024-04-10T02:41:08.980933Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install datasets==2.15","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:11.366992Z","iopub.execute_input":"2024-04-10T02:41:11.367380Z","iopub.status.idle":"2024-04-10T02:41:26.696672Z","shell.execute_reply.started":"2024-04-10T02:41:11.367353Z","shell.execute_reply":"2024-04-10T02:41:26.695695Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting datasets==2.15\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.15)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.15)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (2024.2.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.15)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.0\n    Uninstalling fsspec-2024.3.0:\n      Successfully uninstalled fsspec-2024.3.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ns3fs 2024.3.0 requires fsspec==2024.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(df_mr_train)\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:31.067973Z","iopub.execute_input":"2024-04-10T02:41:31.068886Z","iopub.status.idle":"2024-04-10T02:41:32.374867Z","shell.execute_reply.started":"2024-04-10T02:41:31.068843Z","shell.execute_reply":"2024-04-10T02:41:32.373869Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"11746"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:34.249597Z","iopub.execute_input":"2024-04-10T02:41:34.250493Z","iopub.status.idle":"2024-04-10T02:41:34.258492Z","shell.execute_reply.started":"2024-04-10T02:41:34.250459Z","shell.execute_reply":"2024-04-10T02:41:34.257570Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'source_url': 'https://www.bbc.com/marathi/international-46944888', 'target_url': 'https://www.bbc.com/marathi/international-46944888', 'text': 'गेन्सर टोरोंटोमध्य राहतात आणि त्या 1991पासून शिल्पकला करत आहेत. तब्बल 15 वर्षं अहोरात्र खपून गेन्सर यांनी समुद्रातल्या शिंपल्यांचा चुरा करून अॅडमचं शिल्प तयार केलं. अब्राहम धर्मानुसार अॅडम हा देवानं बनवलेला पहिला मानव मानला जातो. त्यादरम्यानच त्यांना मेंदुच्या Degenerative Autoimmune Disease या विकाराचा सामना करावा लागला. पण हा आजार त्यांना त्यांच्या पेशामुळे झाला हे जेव्हा कळलं तेव्हा फारच उशीर झाला होता. गेन्सर या टोरोंटोमध्य राहतात आणि त्या 1991पासून शिल्पकला करत आहेत. त्या शिल्प बनवण्यासाठी शिंपले, प्रवाळ, सुकलेली पानं आणि कायदेशीर मार्गाने मिळलेली प्राण्याची हाडं यांचा वापर करतात. 1998मध्ये त्यांनी लिलिथ यांचं शिल्प बनवलं. ज्यू लोकांच्या लोककथेप्रमाणे लिलिथ ही शिंपल्यातल्या अंड्यापासून बनलेली पहिली महिला होती. अॅडम यांचं शिल्प निळ्या मझल शिंपल्याच्या घटकांपासून बनवण्याची ही त्यांची स्वत:ची कल्पना होती. कॅनाडाच्या अटलांटिक किनाऱ्याला त्यांनी भेट दिली. तिथून त्यांनी खूप सारे शंख आणि शंपले त्या टोरोंटाला घेऊन गेल्या. गेन्सर यांचं शिल्प हे पूर्णत: नैसर्गिक घटकांपासून बनवलेलं आहे. \"अॅडमच्या शरिराचा आकार बनवण्यासाठी मी दररोज जवळजवळ 12 तास शिंपल्याचा चुरा करून तो चाळून घ्यायचे.\" टोरोंटा लाइफ या नियतकालिकात त्यांनी ही माहिती दिली आहे. \"त्या चुऱ्यामुळे मला अॅडमच्या बरगड्या चांगल्याप्रकारे बनवता आल्या,\" असं त्या सांगतात. शिंपल्यातलं विष कधी निदर्शनास आलं? अॅडमच्या शिल्पावर काही महिने काम केल्यावर गेन्सर यांची तब्येत खालावली. \"मी सारखं चिडू लागली. माझं डोकं सतत दुखू लागलं, उलट्या होऊ लागल्या. कधी कधी दिवसातून अनेक वेळा उलट्या व्हायच्या,\" असं त्या लिहितात. \"मूत्रविकार तज्ज्ञ, सांधेदुखीतज्ज्ञ, अंतस्रावतज्ज्ञ यांच्याकडे माझ्या न संपणाऱ्या फेऱ्या होऊ लागल्या. पण काहीच निदान होत नव्हतं. तुम्ही कुठल्या विषारी पदार्थाच्या संपर्कात आला होता का? असं ते मला विचारायचे. पण मी फक्त नैसर्गिक घटकांचा वापर करते असं सांगायचे.\" मृत्यूच्याआधी गेन्सर यांना अॅडमचं शिल्प तयार करायचं होतं. शिंपल्यांचा चुरा करत असताना काही वेळानंनतर गेन्सर यांना एका जागेवरून हलताही यायचं नाही. त्यांचे स्नायू दुखू लागायचे. मनगटात वेदना व्हायच्या. मृत्यूच्याआधी गेन्सर यांना अॅडमचं शिल्प तयार करायचं होतं. आणि ते त्यांनी करून दाखवलं. \"आता मला खूप अशक्तपणा वाटत आहे. माझं शरीर साथ देत नाहीये. माझ्या मृत्युच्याआधी हे शिल्प व्हावं एवढीच माझी इच्छा होती,\" असं त्यांनी बीबीसीला सांगितलं. तीव्र स्मृतीभ्रंश \"शिल्प पूर्ण व्हायच्याआधीच मला तीव्र प्रकारचा स्मृतीभ्रंभ जाणवू लागला. मला विचार करता येत नव्हता. माझा गोंधळ उडायचा. शिल्पाचे भाग कसे असावेत याविषयी मला विचार करता येत नव्हता. मागची बाजू पुढे लावायचे.\" \"मला राग यायचा. अस्वस्थ वाटायचं, आत्महत्या करायची इच्छा व्हायची. माझा मानसिक तणाव एवढा वाढला की, मी रस्त्यावर येरझाऱ्या घालायचे, मोठ्यानं बडबड करायचे.\" \"मी मनोविकारतज्ज्ञाची भेट घतेली. पण त्यांनाही याविषयी काही समजलं नाही. मी सगळा प्रयत्न केला. अगदी antidepressants, antipsychotics आणि गुंगीची औषधं घेतली, पण काहीही फायदा झाला नाही. एकेदिवशी त्यांना हाडात आणि शिंपल्यात विषारी घटक आढळले. हे घटक वातावरणातून एकवटले होते. त्याचवेळी त्यांना रोगाचा उलगडा झाला. वातावरणातले विषारी घटक शंख आणि शिंपल्यात एकटवले जातात. विषारी शंख शिंपले 2015 पासून गेन्सर यांच्या शरिरात जड धातुंमुळे हळुहळू विष पसरत होतं. \"माझ्या शरीरात मोठ्या प्रमाणात आर्सेनिकचे घटक आढळले. नंतर ते लीड असल्याचं दिसून आलं,\" असं गेन्सर सागंतात. अॅडमच्या शिल्पासाठी दररोज हजारो शंख आणि शिंपल्यांचा केलेला चुरा याला कारणीभूत होतं. शंख आणि शिंपल्यातले काही घटक हे पाण्यातले विषारी घटक आकर्षित करतात. गेन्सर जेव्हा शिंपल्याचा चुरा करायच्या तेव्हा ते विषारी कण हवेत पसरायचे. गेन्सर यांचं शरीर त्याच्या संपर्कात आल्यानंतर त्यांच्या शरीरात हे विषारी घटक परसरले. त्या आपल्या कलाकृतींद्वारे निसर्गाशी मानवाचं किचकट नातं दाखवण्याचं काम करत होत्या, तेही अगदी नैसर्गिक वस्तूंचा वापर करून. पण त्याच कलेतून त्यांची जीवनरेखा खुंटत होती. याला नशिबाने केलेली क्रूर थट्टाच म्हणावी लागेल. \"माझं शरीर हे आपण पृथ्वीत कसं विष पेरतोय याचाच संदेश देत आहे,\" असं त्यांनी टोरोंटा लाइफमध्ये लिहिलं आहे. शिल्पकला चालू ठेवण्यासाठी गेन्सर यांना आता सतत काळजी घ्यावी लागते. \\'माझा सुंदर मृत्यू\\' 2015मध्ये अॅडमचं शिल्प तयार झालं. ते अपूर्ण राहिलं असतं तर त्यांच्या जिवनाला काहीच अर्थ राहिला नसता, असं गेन्सर सांगतात. गेन्सर यांना सध्या मेंदुचा तीव्र विकार आहे, खूप कमी ऐकू येतं, कायमस्वरुपी मानसिक तणाव झाला आहे. त्यांना अल्झायमर पार्किन्सन होण्याची दाट शक्यता आहे. शिल्पकला चालू ठेवण्यासाठी गेन्सर यांना आता सतत काळजी घ्यावी लागते. \"मला याचा पश्चाताप होत नाही. कोणत्याही प्रकारचं दु:ख वाटून न घेता पुढं जायचं असतं,\" असं त्यानी बीबीसीशी बोलताना सांगितलं. \"मला समाधानही वाटतं. कारण तो (अॅडम) भव्य दिसतो. त्यातूनच मला स्फूर्ती मिळते. मी याला माझा सुंदर मृत्यू मानते. \" हेही वाचलंत का? (बीबीसी मराठीचे सर्व अपडेट्स मिळवण्यासाठी तुम्ही आम्हाला फेसबुक, इन्स्टाग्राम, यूट्यूब, ट्विटर वर फॉलो करू शकता.)', 'summary': 'काही शिल्पकारांना त्यांचं शिल्प म्हणजे जीव की प्राण असतं. पण शिल्पकार गिलियन गेन्सर यांच्यावर त्यांनी तयार केलेलं शिल्प जिवावर बेतलं आहे.'}\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_2 = Dataset.from_pandas(df_val_cs_mar)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:37.628180Z","iopub.execute_input":"2024-04-10T02:41:37.628512Z","iopub.status.idle":"2024-04-10T02:41:37.690464Z","shell.execute_reply.started":"2024-04-10T02:41:37.628490Z","shell.execute_reply":"2024-04-10T02:41:37.689621Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = dataset.map(preprocess_function, batched=True)\ntokenized_test_set = dataset_2.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:41:39.869088Z","iopub.execute_input":"2024-04-10T02:41:39.869443Z","iopub.status.idle":"2024-04-10T02:43:17.026436Z","shell.execute_reply.started":"2024-04-10T02:41:39.869416Z","shell.execute_reply":"2024-04-10T02:43:17.025041Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11746 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81969c643df94a0ca8b525e375a6a3c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1254 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"331364fdf97d45a49a89874e1248f29d"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:43:19.932481Z","iopub.execute_input":"2024-04-10T02:43:19.932889Z","iopub.status.idle":"2024-04-10T02:43:40.132909Z","shell.execute_reply.started":"2024-04-10T02:43:19.932842Z","shell.execute_reply":"2024-04-10T02:43:40.132124Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/976M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4276f3860040eab79e35f5cf2fd9ab"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = {'train': dataset, 'val':dataset_2}","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:43:41.983214Z","iopub.execute_input":"2024-04-10T02:43:41.983775Z","iopub.status.idle":"2024-04-10T02:43:41.988167Z","shell.execute_reply.started":"2024-04-10T02:43:41.983745Z","shell.execute_reply":"2024-04-10T02:43:41.987266Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"columns = [\"input_ids\", \"labels\", \"attention_mask\"]\ntokenized_datasets.set_format(type=\"torch\", columns=columns)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:43:44.562906Z","iopub.execute_input":"2024-04-10T02:43:44.563634Z","iopub.status.idle":"2024-04-10T02:43:44.568578Z","shell.execute_reply.started":"2024-04-10T02:43:44.563599Z","shell.execute_reply":"2024-04-10T02:43:44.567490Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(dataset[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:43:46.632017Z","iopub.execute_input":"2024-04-10T02:43:46.632387Z","iopub.status.idle":"2024-04-10T02:43:46.638755Z","shell.execute_reply.started":"2024-04-10T02:43:46.632359Z","shell.execute_reply":"2024-04-10T02:43:46.637863Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"11746"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_test_set.set_format(type=\"torch\", columns=columns)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:43:48.920432Z","iopub.execute_input":"2024-04-10T02:43:48.920777Z","iopub.status.idle":"2024-04-10T02:43:48.925790Z","shell.execute_reply.started":"2024-04-10T02:43:48.920751Z","shell.execute_reply":"2024-04-10T02:43:48.924931Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.gradient_checkpointing_enable()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:43:50.845161Z","iopub.execute_input":"2024-04-10T02:43:50.845833Z","iopub.status.idle":"2024-04-10T02:43:50.851732Z","shell.execute_reply.started":"2024-04-10T02:43:50.845798Z","shell.execute_reply":"2024-04-10T02:43:50.850513Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:44:11.730232Z","iopub.execute_input":"2024-04-10T02:44:11.730693Z","iopub.status.idle":"2024-04-10T02:44:11.735224Z","shell.execute_reply.started":"2024-04-10T02:44:11.730661Z","shell.execute_reply":"2024-04-10T02:44:11.734293Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\nbatch_size = 32\nnum_train_epochs = 8\n# Show the training loss with every epoch\nlogging_steps = len(dataset[\"train\"]) // batch_size\nmodel_name = model_checkpoint.split(\"/\")[-1]\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=f\"{model_name}_new_3\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=0.001,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.00001,\n    fp16=False,\n    save_total_limit=1,\n    save_strategy=\"epoch\",\n    num_train_epochs=num_train_epochs,\n    load_best_model_at_end=True,     # Load the best model at the end of training\n    metric_for_best_model='loss',    # Use loss to identify the best model\n    predict_with_generate=True,\n    push_to_hub=True,\n    gradient_accumulation_steps=32,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:45:03.011012Z","iopub.execute_input":"2024-04-10T02:45:03.011739Z","iopub.status.idle":"2024-04-10T02:45:03.099955Z","shell.execute_reply.started":"2024-04-10T02:45:03.011707Z","shell.execute_reply":"2024-04-10T02:45:03.099010Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns(\n    dataset[\"train\"].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:45:06.226549Z","iopub.execute_input":"2024-04-10T02:45:06.226918Z","iopub.status.idle":"2024-04-10T02:45:06.234342Z","shell.execute_reply.started":"2024-04-10T02:45:06.226888Z","shell.execute_reply":"2024-04-10T02:45:06.233514Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tokenized_test_set = tokenized_test_set.remove_columns(\n    dataset[\"val\"].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:45:08.475528Z","iopub.execute_input":"2024-04-10T02:45:08.475897Z","iopub.status.idle":"2024-04-10T02:45:08.483976Z","shell.execute_reply.started":"2024-04-10T02:45:08.475861Z","shell.execute_reply":"2024-04-10T02:45:08.483126Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets,\n    eval_dataset=tokenized_test_set,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:45:10.924247Z","iopub.execute_input":"2024-04-10T02:45:10.924678Z","iopub.status.idle":"2024-04-10T02:45:12.229793Z","shell.execute_reply.started":"2024-04-10T02:45:10.924643Z","shell.execute_reply":"2024-04-10T02:45:12.229012Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T02:45:23.834104Z","iopub.execute_input":"2024-04-10T02:45:23.834482Z","iopub.status.idle":"2024-04-10T04:51:42.172159Z","shell.execute_reply.started":"2024-04-10T02:45:23.834451Z","shell.execute_reply":"2024-04-10T04:51:42.171127Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240410_024555-jrexzayi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vanmessi888/huggingface/runs/jrexzayi' target=\"_blank\">fresh-plant-7</a></strong> to <a href='https://wandb.ai/vanmessi888/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vanmessi888/huggingface' target=\"_blank\">https://wandb.ai/vanmessi888/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vanmessi888/huggingface/runs/jrexzayi' target=\"_blank\">https://wandb.ai/vanmessi888/huggingface/runs/jrexzayi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [88/88 2:03:35, Epoch 7/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>3.448747</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>2.993308</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>2.831832</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>2.804729</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>2.805658</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=88, training_loss=3.242799932306463, metrics={'train_runtime': 7560.4869, 'train_samples_per_second': 12.429, 'train_steps_per_second': 0.012, 'total_flos': 4.870845632820019e+16, 'train_loss': 3.242799932306463, 'epoch': 7.65})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:52:40.085351Z","iopub.execute_input":"2024-04-10T04:52:40.085725Z","iopub.status.idle":"2024-04-10T04:52:46.995210Z","shell.execute_reply.started":"2024-04-10T04:52:40.085695Z","shell.execute_reply":"2024-04-10T04:52:46.993117Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1712717124.1530285e0282.34.0:   0%|          | 0.00/7.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6eab3f1b6fa40b195c00fe05b9a3795"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/october-sd/IndicBART_new_3/commit/8fb4d475e9b367dbc0d3479fef4778d4b5c4b3f7', commit_message='Training complete', commit_description='', oid='8fb4d475e9b367dbc0d3479fef4778d4b5c4b3f7', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}